{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMuosw3FlMnxdeBzoPpaF3j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2766e53086646d184ec178a34f2b284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86539024d414cd8b5a2fd34b6d7273a",
              "IPY_MODEL_b131a94507e047f282eea4d7f12ec029",
              "IPY_MODEL_339ff63976a14e94a97060f4b1d9d7a7"
            ],
            "layout": "IPY_MODEL_9d1d9400179640e0933fded2723dd12c"
          }
        },
        "e86539024d414cd8b5a2fd34b6d7273a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c99c76cf73d42f18ac67dffc48270bd",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea03ac4fcb34944a39f98c7a30e0d05",
            "value": "Map: 100%"
          }
        },
        "b131a94507e047f282eea4d7f12ec029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc100bd50134566be0e2ae9c4ba1692",
            "max": 20638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_840b99e9155d442ba8a28e96f455cfc2",
            "value": 20638
          }
        },
        "339ff63976a14e94a97060f4b1d9d7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2021701d3f743fead7bda615971d46e",
            "placeholder": "​",
            "style": "IPY_MODEL_b98b832b66e444c6adccc9399da74e78",
            "value": " 20638/20638 [03:36&lt;00:00, 144.16 examples/s]"
          }
        },
        "9d1d9400179640e0933fded2723dd12c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c99c76cf73d42f18ac67dffc48270bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea03ac4fcb34944a39f98c7a30e0d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cc100bd50134566be0e2ae9c4ba1692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840b99e9155d442ba8a28e96f455cfc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2021701d3f743fead7bda615971d46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b98b832b66e444c6adccc9399da74e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinay10110/Pest-Early-Detection/blob/master/PestDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    ViTImageProcessor,\n",
        "    ViTForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import evaluate\n",
        "from collections import Counter\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: Load and Explore Dataset\n",
        "# =============================================================================\n",
        "# Load your dataset\n",
        "ds = load_dataset(\"ButterChicken98/plantvillage-image-text-pairs\")\n",
        "print(\"Dataset structure:\")\n",
        "print(ds)\n",
        "\n",
        "# Explore the data\n",
        "print(f\"\\nNumber of training samples: {len(ds['train'])}\")\n",
        "print(f\"Sample data structure: {ds['train'][0].keys()}\")\n",
        "\n",
        "# Look at a few examples\n",
        "for i in range(3):\n",
        "    sample = ds['train'][i]\n",
        "    print(f\"\\nSample {i+1}:\")\n",
        "    print(f\"Caption: {sample['caption']}\")\n",
        "    if 'captions' in sample:\n",
        "        print(f\"Captions list: {sample['captions']}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: Prepare Labels and Create Label Mappings\n",
        "# =============================================================================\n",
        "# Extract unique labels from captions\n",
        "all_captions = [item['caption'] for item in ds['train']]\n",
        "unique_labels = list(set(all_captions))\n",
        "unique_labels.sort()  # Sort for consistency\n",
        "\n",
        "print(f\"\\nFound {len(unique_labels)} unique classes:\")\n",
        "for i, label in enumerate(unique_labels[:10]):  # Show first 10\n",
        "    print(f\"{i}: {label}\")\n",
        "\n",
        "# Create label mappings\n",
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "id2label = {idx: label for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "print(f\"\\nLabel distribution:\")\n",
        "label_counts = Counter(all_captions)\n",
        "for label, count in sorted(label_counts.items())[:5]:  # Show top 5\n",
        "    print(f\"{label}: {count} samples\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: Load Pre-trained Model and Processor\n",
        "# =============================================================================\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "# Load model with the correct number of classes\n",
        "num_labels = len(unique_labels)\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True  # Important for different number of classes\n",
        ")\n",
        "\n",
        "print(f\"Model loaded with {num_labels} classes\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: Data Preprocessing\n",
        "# =============================================================================\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"Preprocess images and labels for training\"\"\"\n",
        "    # Process images\n",
        "    images = [image.convert(\"RGB\") for image in examples['image']]\n",
        "    inputs = processor(images, return_tensors=\"pt\")\n",
        "\n",
        "    # Process labels\n",
        "    labels = [label2id[caption] for caption in examples['caption']]\n",
        "    inputs['labels'] = torch.tensor(labels)\n",
        "\n",
        "    return inputs\n",
        "\n",
        "# Apply preprocessing\n",
        "print(\"Preprocessing dataset...\")\n",
        "processed_dataset = ds['train'].map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    batch_size=32,\n",
        "    remove_columns=ds['train'].column_names\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: Split Dataset into Train/Validation\n",
        "# =============================================================================\n",
        "# Split dataset (80% train, 20% validation)\n",
        "train_test_split = processed_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(eval_dataset)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: Define Metrics\n",
        "# =============================================================================\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    # Calculate precision, recall, f1\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy['accuracy'],\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: Training Configuration\n",
        "# =============================================================================\n",
        "# Create output directory\n",
        "output_dir = \"./vit-plantvillage-finetuned\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=16,  # Adjust based on GPU memory\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,  # Start with fewer epochs\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        "    report_to=None,  # Disable wandb logging\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    dataloader_pin_memory=False,  # Can help with memory issues\n",
        ")\n",
        "\n",
        "print(\"Training configuration:\")\n",
        "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"Learning rate: {training_args.learning_rate}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: Initialize Trainer and Start Training\n",
        "# =============================================================================\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor,  # For saving preprocessing info\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"This may take a while depending on your dataset size and GPU...\")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: Evaluate the Model\n",
        "# =============================================================================\n",
        "print(\"\\nEvaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: Save the Model\n",
        "# =============================================================================\n",
        "print(f\"\\nSaving model to {output_dir}\")\n",
        "trainer.save_model()\n",
        "processor.save_pretrained(output_dir)\n",
        "\n",
        "print(\"Training completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a2766e53086646d184ec178a34f2b284",
            "e86539024d414cd8b5a2fd34b6d7273a",
            "b131a94507e047f282eea4d7f12ec029",
            "339ff63976a14e94a97060f4b1d9d7a7",
            "9d1d9400179640e0933fded2723dd12c",
            "1c99c76cf73d42f18ac67dffc48270bd",
            "9ea03ac4fcb34944a39f98c7a30e0d05",
            "9cc100bd50134566be0e2ae9c4ba1692",
            "840b99e9155d442ba8a28e96f455cfc2",
            "e2021701d3f743fead7bda615971d46e",
            "b98b832b66e444c6adccc9399da74e78"
          ]
        },
        "id": "u2203-LsNs4t",
        "outputId": "ec316fd2-099e-4a0b-b3b9-ef71dfb508cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Dataset structure:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'caption', 'captions'],\n",
            "        num_rows: 20638\n",
            "    })\n",
            "})\n",
            "\n",
            "Number of training samples: 20638\n",
            "Sample data structure: dict_keys(['image', 'caption', 'captions'])\n",
            "\n",
            "Sample 1:\n",
            "Caption: Tomato healthy\n",
            "Captions list: ['A vibrant green and healthy tomato leaf with smooth, spotless surface.', 'A healthy Solanum lycopersicum leaf, free of disease or pests, with a uniform green color.', 'A fresh tomato leaf outdoors, glowing in sunlight with a smooth and unblemished surface.', 'A clean and healthy tomato leaf image, perfect for comparison in plant health datasets.']\n",
            "\n",
            "Sample 2:\n",
            "Caption: Tomato Late blight\n",
            "Captions list: ['A tomato leaf showing dark brown lesions and water-soaked edges, symptoms of late blight disease.', 'A tomato leaf infected with Phytophthora infestans, featuring characteristic necrotic patches and chlorosis.', 'A tomato plant leaf outdoors, visibly damaged by late blight with brown spots and wilting edges.', 'A labeled image of a tomato leaf affected by late blight, suitable for agricultural disease datasets.']\n",
            "\n",
            "Sample 3:\n",
            "Caption: Tomato healthy\n",
            "Captions list: ['A vibrant green and healthy tomato leaf with smooth, spotless surface.', 'A healthy Solanum lycopersicum leaf, free of disease or pests, with a uniform green color.', 'A fresh tomato leaf outdoors, glowing in sunlight with a smooth and unblemished surface.', 'A clean and healthy tomato leaf image, perfect for comparison in plant health datasets.']\n",
            "\n",
            "Found 15 unique classes:\n",
            "0: Pepper bell Bacterial spot\n",
            "1: Pepper bell healthy\n",
            "2: Potato Early blight\n",
            "3: Potato Late blight\n",
            "4: Potato healthy\n",
            "5: Tomato Bacterial spot\n",
            "6: Tomato Early blight\n",
            "7: Tomato Late blight\n",
            "8: Tomato Leaf Mold\n",
            "9: Tomato Septoria leaf spot\n",
            "\n",
            "Label distribution:\n",
            "Pepper bell Bacterial spot: 997 samples\n",
            "Pepper bell healthy: 1478 samples\n",
            "Potato Early blight: 1000 samples\n",
            "Potato Late blight: 1000 samples\n",
            "Potato healthy: 152 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([15]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([15, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 15 classes\n",
            "Preprocessing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20638 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2766e53086646d184ec178a34f2b284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 16510\n",
            "Validation samples: 4128\n",
            "Training configuration:\n",
            "Batch size: 16\n",
            "Epochs: 3\n",
            "Learning rate: 2e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3203620504.py:175: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "This may take a while depending on your dataset size and GPU...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3096' max='3096' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3096/3096 2:46:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.146600</td>\n",
              "      <td>0.132067</td>\n",
              "      <td>0.968266</td>\n",
              "      <td>0.968632</td>\n",
              "      <td>0.970216</td>\n",
              "      <td>0.968266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.036800</td>\n",
              "      <td>0.025396</td>\n",
              "      <td>0.992733</td>\n",
              "      <td>0.992732</td>\n",
              "      <td>0.992779</td>\n",
              "      <td>0.992733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.024440</td>\n",
              "      <td>0.992490</td>\n",
              "      <td>0.992499</td>\n",
              "      <td>0.992613</td>\n",
              "      <td>0.992490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.015333</td>\n",
              "      <td>0.996124</td>\n",
              "      <td>0.996126</td>\n",
              "      <td>0.996178</td>\n",
              "      <td>0.996124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.009313</td>\n",
              "      <td>0.997335</td>\n",
              "      <td>0.997331</td>\n",
              "      <td>0.997346</td>\n",
              "      <td>0.997335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.008812</td>\n",
              "      <td>0.997335</td>\n",
              "      <td>0.997333</td>\n",
              "      <td>0.997353</td>\n",
              "      <td>0.997335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [258/258 08:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n",
            "eval_loss: 0.0153\n",
            "eval_accuracy: 0.9961\n",
            "eval_f1: 0.9961\n",
            "eval_precision: 0.9962\n",
            "eval_recall: 0.9961\n",
            "eval_runtime: 492.6753\n",
            "eval_samples_per_second: 8.3790\n",
            "eval_steps_per_second: 0.5240\n",
            "epoch: 3.0000\n",
            "\n",
            "Saving model to ./vit-plantvillage-finetuned\n",
            "Training completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# =============================================================================\n",
        "# METHOD 1: Download as ZIP file (Recommended)\n",
        "# =============================================================================\n",
        "def create_model_zip(model_dir=\"./vit-plantvillage-finetuned\", zip_name=\"vit-plantvillage-model.zip\"):\n",
        "    \"\"\"Create a ZIP file of the model directory and download it\"\"\"\n",
        "\n",
        "    # Check if model directory exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        print(f\"Error: Model directory {model_dir} not found!\")\n",
        "        return\n",
        "\n",
        "    # Create ZIP file\n",
        "    print(f\"Creating ZIP file: {zip_name}\")\n",
        "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(model_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Add file to ZIP with relative path\n",
        "                arcname = os.path.relpath(file_path, os.path.dirname(model_dir))\n",
        "                zipf.write(file_path, arcname)\n",
        "                print(f\"Added: {arcname}\")\n",
        "\n",
        "    print(f\"ZIP file created successfully!\")\n",
        "    print(f\"File size: {os.path.getsize(zip_name) / (1024*1024):.1f} MB\")\n",
        "# Create and download the model ZIP\n",
        "create_model_zip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nxsvmrw44-7",
        "outputId": "247fdfe4-b57e-4f44-e6eb-808fc613cea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating ZIP file: vit-plantvillage-model.zip\n",
            "Added: vit-plantvillage-finetuned/config.json\n",
            "Added: vit-plantvillage-finetuned/model.safetensors\n",
            "Added: vit-plantvillage-finetuned/training_args.bin\n",
            "Added: vit-plantvillage-finetuned/preprocessor_config.json\n",
            "Added: vit-plantvillage-finetuned/runs/Aug15_10-18-25_f118b448f514/events.out.tfevents.1755253107.f118b448f514.700.11\n",
            "Added: vit-plantvillage-finetuned/runs/Aug15_10-18-25_f118b448f514/events.out.tfevents.1755263613.f118b448f514.700.12\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/optimizer.pt\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/config.json\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/trainer_state.json\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/model.safetensors\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/rng_state.pth\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/scheduler.pt\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/training_args.bin\n",
            "Added: vit-plantvillage-finetuned/checkpoint-3096/preprocessor_config.json\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/optimizer.pt\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/config.json\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/trainer_state.json\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/model.safetensors\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/rng_state.pth\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/scheduler.pt\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/training_args.bin\n",
            "Added: vit-plantvillage-finetuned/checkpoint-2000/preprocessor_config.json\n",
            "ZIP file created successfully!\n",
            "File size: 2118.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Download just the essential files\n",
        "files.download('./vit-plantvillage-finetuned/config.json')\n",
        "files.download('./vit-plantvillage-finetuned/model.safetensors')\n",
        "files.download('./vit-plantvillage-finetuned/preprocessor_config.json')\n",
        "files.download('./vit-plantvillage-finetuned/training_args.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Pa_c9aDn7Cv7",
        "outputId": "a0662ee0-c16d-4c0f-f1fb-15938e40f61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2da7efb2-fd2f-4a00-8b3d-d757aebca2b3\", \"config.json\", 1656)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3bf660f9-cc14-4918-8842-797ddef66db6\", \"model.safetensors\", 343263964)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81f5ab30-5b7b-45ba-92e2-a5a3c690b188\", \"preprocessor_config.json\", 351)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac7aab7f-9600-44ad-9218-3286c6e17f13\", \"training_args.bin\", 5368)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "\n",
        "MODEL_FILE = \"./model.safetensors\"   # or pytorch_model.bin\n",
        "CONFIG_FILE = \"./config.json\"\n",
        "PROCESSOR_FILE = \"./preprocessor_config.json\"\n",
        "\n",
        "print(\"Loading your trained model...\")\n",
        "try:\n",
        "    # Load the model and processor\n",
        "    model = ViTForImageClassification.from_pretrained(\n",
        "        \"./\",\n",
        "        local_files_only=True,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    processor = ViTImageProcessor.from_pretrained(\n",
        "        \"./\",\n",
        "        local_files_only=True\n",
        "    )\n",
        "\n",
        "    print(\"✅ Model loaded successfully!\")\n",
        "    print(f\"📊 Model can classify {len(model.config.id2label)} different plant conditions\")\n",
        "\n",
        "    # Show some example classes\n",
        "    print(\"\\n🏷️ Some classes your model can identify:\")\n",
        "    class_names = list(model.config.id2label.values())\n",
        "    for i, class_name in enumerate(class_names[:10]):  # Show first 10\n",
        "        print(f\"  {i}: {class_name}\")\n",
        "    if len(class_names) > 10:\n",
        "        print(f\"  ... and {len(class_names)-10} more classes\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: PREDICTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def predict_plant_disease(image_path, model, processor, top_k=5):\n",
        "    \"\"\"\n",
        "    Predict plant disease from an image\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the image file\n",
        "        model: Loaded ViT model\n",
        "        processor: Image processor\n",
        "        top_k: Number of top predictions to show\n",
        "\n",
        "    Returns:\n",
        "        predictions: List of (class_name, confidence) tuples\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        print(f\"📷 Image loaded: {image.size} pixels\")\n",
        "\n",
        "        # Process the image\n",
        "        inputs = processor(image, return_tensors=\"pt\")\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        # Get top-k predictions\n",
        "        top_predictions = torch.topk(predictions, top_k)\n",
        "\n",
        "        results = []\n",
        "        for i in range(top_k):\n",
        "            class_idx = top_predictions.indices[0][i].item()\n",
        "            confidence = top_predictions.values[0][i].item()\n",
        "            class_name = model.config.id2label[class_idx]\n",
        "            results.append((class_name, confidence))\n",
        "\n",
        "        return results, image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing image: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: TEST WITH AN IMAGE\n",
        "# =============================================================================\n",
        "\n",
        "def test_model():\n",
        "    \"\"\"Test the model with an uploaded image\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🧪 TESTING YOUR MODEL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Upload a plant image to test\n",
        "    print(\"📤 Upload a plant image to test your model...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        # Get the uploaded image path\n",
        "        image_path = list(uploaded.keys())[0]\n",
        "        print(f\"✅ Image uploaded: {image_path}\")\n",
        "\n",
        "        # Make prediction\n",
        "        print(f\"🔮 Making prediction on: {image_path}\")\n",
        "        results, image = predict_plant_disease(image_path, model, processor, top_k=5)\n",
        "\n",
        "        if results:\n",
        "            print(\"\\n🎯 PREDICTION RESULTS:\")\n",
        "            print(\"-\" * 40)\n",
        "            for i, (class_name, confidence) in enumerate(results, 1):\n",
        "                print(f\"{i}. {class_name}\")\n",
        "                print(f\"   Confidence: {confidence:.4f} ({confidence*100:.1f}%)\")\n",
        "                print()\n",
        "\n",
        "            # Print top prediction\n",
        "            top_class, top_confidence = results[0]\n",
        "            print(f\"🏆 TOP PREDICTION: {top_class}\")\n",
        "            print(f\"🎯 CONFIDENCE: {top_confidence*100:.1f}%\")\n",
        "\n",
        "            if top_confidence > 0.8:\n",
        "                print(\"✅ High confidence prediction!\")\n",
        "            elif top_confidence > 0.5:\n",
        "                print(\"⚠️ Moderate confidence prediction\")\n",
        "            else:\n",
        "                print(\"❓ Low confidence - model is uncertain\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No image uploaded. Please upload an image to test the model.\")\n",
        "\n",
        "# =============================================================================\n",
        "# RUN THE TEST\n",
        "# =============================================================================\n",
        "\n",
        "# Test the model\n",
        "test_model()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 MODEL TESTING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"💡 Tips for better results:\")\n",
        "print(\"• Use clear, well-lit plant images\")\n",
        "print(\"• Ensure the plant/disease is the main subject\")\n",
        "print(\"• Images similar to your training data work best\")\n",
        "print(\"• Try different angles if confidence is low\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HQ55SDPp7nC7",
        "outputId": "84378730-60fa-41cc-eb35-90afc0e42bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading your trained model...\n",
            "✅ Model loaded successfully!\n",
            "📊 Model can classify 15 different plant conditions\n",
            "\n",
            "🏷️ Some classes your model can identify:\n",
            "  0: Pepper bell Bacterial spot\n",
            "  1: Pepper bell healthy\n",
            "  2: Potato Early blight\n",
            "  3: Potato Late blight\n",
            "  4: Potato healthy\n",
            "  5: Tomato Bacterial spot\n",
            "  6: Tomato Early blight\n",
            "  7: Tomato Late blight\n",
            "  8: Tomato Leaf Mold\n",
            "  9: Tomato Septoria leaf spot\n",
            "  ... and 5 more classes\n",
            "\n",
            "============================================================\n",
            "🧪 TESTING YOUR MODEL\n",
            "============================================================\n",
            "📤 Upload a plant image to test your model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dac13e5a-a4d1-4bae-8c02-e381cd726ab5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dac13e5a-a4d1-4bae-8c02-e381cd726ab5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 8acca2d85efee656d8cf914ccc512d3a.jpeg to 8acca2d85efee656d8cf914ccc512d3a.jpeg\n",
            "✅ Image uploaded: 8acca2d85efee656d8cf914ccc512d3a.jpeg\n",
            "🔮 Making prediction on: 8acca2d85efee656d8cf914ccc512d3a.jpeg\n",
            "📷 Image loaded: (500, 331) pixels\n",
            "\n",
            "🎯 PREDICTION RESULTS:\n",
            "----------------------------------------\n",
            "1. Tomato Early blight\n",
            "   Confidence: 0.6485 (64.9%)\n",
            "\n",
            "2. Tomato Late blight\n",
            "   Confidence: 0.1301 (13.0%)\n",
            "\n",
            "3. Pepper bell Bacterial spot\n",
            "   Confidence: 0.0688 (6.9%)\n",
            "\n",
            "4. Tomato Septoria leaf spot\n",
            "   Confidence: 0.0441 (4.4%)\n",
            "\n",
            "5. Potato Early blight\n",
            "   Confidence: 0.0350 (3.5%)\n",
            "\n",
            "🏆 TOP PREDICTION: Tomato Early blight\n",
            "🎯 CONFIDENCE: 64.9%\n",
            "⚠️ Moderate confidence prediction\n",
            "\n",
            "============================================================\n",
            "🎉 MODEL TESTING COMPLETE!\n",
            "============================================================\n",
            "💡 Tips for better results:\n",
            "• Use clear, well-lit plant images\n",
            "• Ensure the plant/disease is the main subject\n",
            "• Images similar to your training data work best\n",
            "• Try different angles if confidence is low\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/vit-plantvillage-model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kCrv7pt69syr",
        "outputId": "02a5df7e-0d93-42e8-84c6-6ceeb1d0fa06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9d9bdb57-763c-4b2f-ab50-521f70efb38e\", \"vit-plantvillage-model.zip\", 2221623473)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}